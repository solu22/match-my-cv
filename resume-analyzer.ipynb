{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNP/oc+/VrORiExbBTtN+aT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solu22/match-my-cv/blob/development/resume-analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwpzu1AMqvJy"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "job_1 = \"You will be part of our Patent Transactions team in Technology Standards.  Our team is mostly focused on securing the best possible patent acquisitions (and related) at the earliest possible dates that are consistent with Technology Standards strategy. We are looking for a Software Developer with expertise in artificial intelligence (AI) and machine learning (ML) to optimize software tools for patent acquisition-related analysis.  In this role, you will optimize software solutions on approved platforms that integrate the latest AI and ML methods into patent analysis workflows. You will work with massive datasets—including global patent collections, technical standards, scientific literature, and other technical documents—and optimize tools that automate and enhance tasks such as patent categorization, prior art relevance assessment, technology mapping, and large-scale document evaluation.  You will collaborate closely with patent acquisition specialists, data scientists, and domain experts to optimize high-impact tools that scale across millions of documents.\"\n",
        "job_2 = \"Hitachi Energy is committed to creating a sustainable, flexible, and secure energy system. We need talented people from different backgrounds, genders, and cultures to achieve our purpose of advancing a sustainable energy future for all. Our goal is to attract diverse talent by providing learning opportunity during the summer for students at all levels in Finland.\"\n",
        "job_3 = \"As a Software Engineer, you will be instrumental in the evolution of our sales configuration tool. This role focuses on the crucial daily maintenance of complex configuration rules to ensure seamless functionality and an optimal user experience, alongside hands-on development work in Java. You will contribute to a modern, agile environment, enhancing our core product.\"\n",
        "\n",
        "\n",
        "job_descriptions = {\"desc1\": job_1, \"desc2\": job_2, \"desc3\": job_3}\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(filename)\n",
        "print(f\" File {filename} uplaoded succussfully\")\n",
        "\n",
        "\n",
        "def match_job(file, job_desc):\n",
        "  #Load CV\n",
        "  try:\n",
        "    df = pd.read_excel(file)\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading Excel file: {e}\")\n",
        "    return\n",
        "  skills_row = df[df['Section'].str.contains('Skills', case=False, na=False)]\n",
        "\n",
        "# Extract candidate skills\n",
        "  if skills_row.empty:\n",
        "    print(\"Error: Could not find a row labeled 'Skills' in the 'Section' column\")\n",
        "    return\n",
        "  skills_text = skills_row.iloc[0]['Details']\n",
        "\n",
        "#Prompt generation\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "You are an HR analyst. Your job is to compare a candidate’s CV skills with a set of job descriptions.\n",
        "Use ONLY the skills listed in the CV. Do NOT infer any skills not mentioned explicitly.\n",
        "\n",
        "RULES:\n",
        "- Do NOT hallucinate or assume skills not in the CV.\n",
        "- Use ONLY the candidate’s listed skills.\n",
        "- Compare the two lists mathematically:\n",
        "     - MATCH = (Candidate Skills) INTERSECT (Job Requirements)\n",
        "     - MISSING = (Job Requirements) MINUS (Candidate Skills)\n",
        "- Return VALID JSON ONLY. Do not include markdown or explanations outside JSON.\n",
        "- Keep summaries concise and factual.\n",
        "\n",
        "STANDARDIZATION:\n",
        "- Technical Skills: programming languages, AI/ML tools, frameworks, domain-specific software.\n",
        "- Domain Knowledge: industry-specific concepts, standards, processes, terminology.\n",
        "- Relevance: How well the candidate’s skills match the job description.\n",
        "- Gaps: Skills mentioned in the job but missing in the CV.\n",
        "\n",
        "OUTPUT STRUCTURE:\n",
        "Return JSON with these fields for each job:\n",
        "\n",
        "{{\n",
        "  \"candidate_skills\": [list of skills exactly as in CV],\n",
        "  \"job_matches\": {{\n",
        "    \"job_id\": {{\n",
        "      \"strengths\": [skills listed in the candidate_skills that MATCH requirements in the job description],\n",
        "      \"weaknesses\": [keywords in the job description missing from candidate skills],\n",
        "      \"suggestions\": [practical advice to improve skills or fill gaps]\n",
        "    }}\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Candidate Skills:\n",
        "  {skills_text}\n",
        "\n",
        "Job Descriptions:\n",
        "  {json.dumps(job_descriptions, indent=2)}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Gemini configuration\n",
        "\n",
        "  API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "  print(\"API Key loaded:\", bool(API_KEY))\n",
        "  client = genai.Client(api_key= API_KEY)\n",
        "  try:\n",
        "    response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents = prompt,\n",
        "      )\n",
        "    result_text = response.text.strip()\n",
        "  except Exception as e:\n",
        "    print(f\"Error calling Gemini API: {e}\")\n",
        "    return\n",
        "\n",
        "#Clean Gemini response\n",
        "  clean_result = re.sub(r'```json\\n', '', result_text) # remove starting ```json\n",
        "  clean_result = re.sub(r\"\\n```$\", \"\", clean_result)      # remove ending ```\n",
        "  clean_result = clean_result.strip()\n",
        "\n",
        "  try:\n",
        "    result_dict = json.loads(clean_result)\n",
        "    print(\"Json parsed successfully\")\n",
        "  except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON: {e}\")\n",
        "    return\n",
        "\n",
        "  if result_dict:\n",
        "    candidate_skills = result_dict.get(\"candidate_skills\", [])\n",
        "    job_matches = result_dict.get(\"job_matches\", {})\n",
        "\n",
        "    print(\"\\nCandidate Skills:\", candidate_skills)\n",
        "\n",
        "    for job_id, job_info in job_matches.items():\n",
        "        print(f\"\\nJob ID: {job_id}\")\n",
        "        print(\"Strengths:\", \" , \".join(job_info.get(\"strengths\", [])))\n",
        "        print(\"Weaknesses:\", \" , \".join(job_info.get(\"weaknesses\", [])))\n",
        "        print(\"Suggestions:\", \" , \".join(job_info.get(\"suggestions\", [])))\n",
        "  else:\n",
        "    print(\"No data returned from Gemini.\")\n",
        "\n",
        "\n",
        "match_job(filename,job_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVGxrfiIs9bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JpWsRTzs967"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}